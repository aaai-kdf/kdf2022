---
title: "The AAAI-21 Workshop on Knowledge Discovery from Unstructured Data in Financial Services"
layout: single
permalink: /hannaneh
classes: wide
sidebar:
 - title    : "Hannaneh Hajishirzi"
   image    : /assets/images/Hanna.jpg
   text     : "Assistant Professor - Paul G. Allen School of Computer Science and Engineering, University of Washington, and Research Fellow, Allen Institute for AI"
header:
  overlay_image: "/assets/images/home_splash_nyc.png"
  #caption: 'Photo by <a href="me">me</a> on <a href="me">me</a>'
---
<h2>Bio</h2>

Hanna Hajishirzi is an Assistant Professor in the Paul G. Allen School of Computer Science & Engineering at the University of Washington and a Research Fellow at the Allen Institute for AI. Her research spans different areas in NLP and AI, focusing on developing machine learning algorithms that represent, comprehend, and reason about diverse forms of data at large scale. Applications for these algorithms include question answering, reading comprehension, representation learning, knowledge extraction, and conversational dialogue. Honors include the Sloan Fellowship, Allen Distinguished Investigator Award, Intel rising star award, multiple best paper and honorable mention awards, and several industry research faculty awards. Hanna received her PhD from University of Illinois and spent a year as a postdoc at Disney Research and CMU.


<h2 id="keynote">Keynote: Knowledge Extraction from Unstructured Scientific Text</h2>

Enormous amounts of ever-changing  knowledge are available online in diverse textual styles (e.g., news vs. science text). This talk presents the question of textual comprehension and reasoning for scientific text, presenting a general framework for extracting information about entities, relations, and events from scientific text. Recent advances in deep learning algorithms, large-scale datasets, and industry-scale computational resources are spurring progress in many Natural Language Processing (NLP) tasks. Nevertheless, current models lack the ability to understand scientific text when task-annotated training data are scarce and computational resources are limited. Our general-purpose knowledge extraction system (called DyGIE) is a multi-task learning framework for tasks of entity recognition, relation extraction, and event extraction. It accomplishes all tasks by enumerating, refining, and scoring text spans designed to capture local (within-sentence) and global (cross-sentence) context. Our framework achieves state of the art results in several datasets with small-scale training data including scientific papers in computer science and Covid-19. Finally, we show that our DyGIE framework can be used to construct a knowledge base of Covid-19 mechanisms, supporting interdisciplinary scientific search over COVID-19 literature, outperforming the prominent PubMed search in a study with clinical experts.